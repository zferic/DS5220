{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle two arrays in unison\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input E\n",
    "\n",
    "#error functions\n",
    "def l1norm(E,l):\n",
    "    return sum([x**2 for x in E])\n",
    "\n",
    "#mean absolute error\n",
    "def mean_absolute_error(E,l):\n",
    "    return 1/len(E) * sum([np.abs(x) for x in E])\n",
    "\n",
    "#huber loss\n",
    "def huber_loss(E, l):\n",
    "    result = []\n",
    "    for e in E:\n",
    "        if e <= l:\n",
    "            result.append( 1/2 * e**2 )\n",
    "        elif e > l:\n",
    "            result.append( l * np.abs(e) - 1/2 * l**2)\n",
    "    return sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zferic85/365.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(-2,2,50)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "def huberfun(x,h):\n",
    "\n",
    "    if np.abs(x) <= h:\n",
    "        return x**2\n",
    "    if np.abs(x) > h:\n",
    "        return h*np.abs(x)\n",
    "\n",
    "x = np.sort(x)\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y =[ e**2 for e in x],\n",
    "    mode = 'lines',\n",
    "    name = 'square'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = [ np.abs(y) for y in x],\n",
    "    mode = 'lines',\n",
    "    name = 'mean'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = x,\n",
    "    y = [huberfun(y,.1) for y in x] ,\n",
    "    mode = 'lines',\n",
    "    name = 'huber .1'\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = x,\n",
    "    y = [huberfun(y,4.1) for y in x] ,\n",
    "    mode = 'lines',\n",
    "    name = 'huber 4.1'\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "py.iplot(data, filename='line-mode')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line search\n",
    "n_max = 1.0\n",
    "r = .6\n",
    "tolerance = .0001\n",
    "max_backtrack_iterations = 50\n",
    "def line_search(w_t, c, g,h):\n",
    "        n = n_max\n",
    "        w = w_t\n",
    "        #this also depends on the loss function why we pass the c\n",
    "        obj = c(np.matmul(data,w)-np.array(target),h)\n",
    "        backtrack_iterations = 0\n",
    "        while backtrack_iterations < max_backtrack_iterations:\n",
    "            w = np.array(w_t) - n * np.array(g)\n",
    "            \n",
    "            if c(np.matmul(data,w)-np.array(target),h) < (obj - tolerance):\n",
    "                break\n",
    "            n = r*n\n",
    "            \n",
    "            backtrack_iterations += 1\n",
    "           \n",
    "        if backtrack_iterations == max_backtrack_iterations - 1:\n",
    "            print('here')\n",
    "            return w_t, 0\n",
    "            \n",
    "        \n",
    "        return w, n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivative of the mean absolute error\n",
    "def mean_absolute_err_g(data,w,target):\n",
    "    g = []\n",
    "    errors = (np.matmul(data,w)-np.array(target))\n",
    "    for p in range(0, len(data[0])):\n",
    "        sums = 0\n",
    "        for idx, e in enumerate(errors):\n",
    "            if e > 0:\n",
    "                sums += data[idx][p]   \n",
    "            if e < 0:\n",
    "                sums -= data[idx][p]\n",
    "            if e == 0:\n",
    "                sums += 0\n",
    "                    \n",
    "        g.append(sums)\n",
    "    return g\n",
    "\n",
    "#derivative of huber loss\n",
    "def huber_loss_g(data,w,target,h):\n",
    "    g = []\n",
    "    errors = (np.matmul(data,w)-np.array(target))\n",
    "    for p in range(0, len(data[0])):\n",
    "        sums = 0\n",
    "        for idx, e in enumerate(errors):\n",
    "            \n",
    "            if np.abs(e) <= h:\n",
    "                \n",
    "                sums += e * data[idx][p]\n",
    "            \n",
    "            if np.abs(e) > h:\n",
    "            \n",
    "                if e > 0:\n",
    "                    sums += h*data[idx][p]   \n",
    "                if e < 0:\n",
    "                    sums -= h*data[idx][p]\n",
    "                if e == 0:\n",
    "                    sums += 0\n",
    "                    \n",
    "        g.append(sums)\n",
    "    return g\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9110630235342279, 0.2708261141812398, 0.13570731441856598]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.random.randn(1,3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch  gradient descent implementation\n",
    "def batch_gradient(data,target,errfun,h):\n",
    "    #initialize w\n",
    "    w = list(np.random.randn(1,len(data[0]))[0])\n",
    "    #super large int (inf)\n",
    "    err = 5000000000000\n",
    "    tolerance = .0001\n",
    "    dim = len(data[0])\n",
    "    max_iterations = 1000\n",
    "    iteration = 0\n",
    "    \n",
    "    while err > tolerance and iteration < max_iterations:\n",
    "        err = errfun(np.matmul(data,w)-np.array(target),h)\n",
    "        #gradient depends on the loss function used\n",
    "        if errfun == l1norm:\n",
    "            g =  np.matmul(np.transpose(data) ,(np.matmul(data,w)-np.array(target)))\n",
    "        if errfun == mean_absolute_error:\n",
    "            g = mean_absolute_err_g(data,w,target)\n",
    "        #huber loss is a combination of the l1norm and absolute so the gradient is piecewise for | y_p - y_t | <= h   \n",
    "        if errfun == huber_loss:\n",
    "            g = huber_loss_g(data,w,target,h)      \n",
    "        #insert line search here for the step size  \n",
    "        #w_ls,n = line_search(w, errfun, g,h)\n",
    "        n = .001\n",
    "        #print(n)\n",
    "        w = np.array(w) - n * np.array(g)\n",
    "        iteration += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic gradient descent\n",
    "def stochastic_gradient(data,target,errfun,epochs):\n",
    "\n",
    "    #initialize w\n",
    "    \n",
    "    w = list(np.random.randn(1,len(data[0]))[0])\n",
    "    \n",
    "\n",
    "    #stochastic gradient descent implementation \n",
    "    hub_coef = .9\n",
    "    for i in range(1,epochs):\n",
    "        data, target = unison_shuffled_copies(np.array(data),np.array(target))\n",
    "        #number of epochs in \n",
    "        for j in range(0, len(data)):\n",
    "            obj = np.matmul(np.transpose(data[j]), w) - target[j]\n",
    "            if errfun == l1norm:\n",
    "                g = obj * data[j]\n",
    "            if errfun == mean_absolute_error:\n",
    "                if obj > 0:\n",
    "                    g = data[j]\n",
    "                if obj < 0:\n",
    "                    g = -data[j]\n",
    "                if obj == 0:\n",
    "                    g = 0\n",
    "            if errfun == huber_loss:\n",
    "                if obj < hub_coef:\n",
    "                    g = obj * data[j]\n",
    "                if obj >= hub_coef:\n",
    "                    if obj > 0:\n",
    "                        g = hub_coef*data[j]\n",
    "                    if obj < 0:\n",
    "                        g = -hub_coef*data[j]\n",
    "                    if obj == 0:\n",
    "                        g = 0\n",
    "            n = 1/i\n",
    "            w = np.array(w) - n * np.array(g)   \n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic(data,target):\n",
    "    \n",
    "    s1 = np.linalg.inv(np.matmul(np.transpose(data),np.array(data)))\n",
    "    s2 = np.matmul(s1,np.transpose(data))\n",
    "    s3 = np.matmul(s2, target)\n",
    "    coef_pred = s3\n",
    "    \n",
    "    return coef_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a1\n",
      "5a2\n",
      "5a3\n"
     ]
    }
   ],
   "source": [
    "#####testing\n",
    "#Problem 5a\n",
    "\n",
    "rez5a1 = []\n",
    "#analyti square loss\n",
    "print('5a1')\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = analytic(data,target)\n",
    "    #w = batch_gradient(data,target,huber_loss,8000)\n",
    "\n",
    "    d = []\n",
    "    rez5a1.append(w[1])\n",
    "#Problem 5b batch square loss\n",
    "rez5a2 = []\n",
    "print('5a2')\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = batch_gradient(data,target,l1norm,8000)\n",
    "    rez5a2.append(w[1])\n",
    "#Problem 5c stochastic_square loss\n",
    "rez5a3 = []\n",
    "print('5a3')\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = stochastic_gradient(data,target,l1norm,100)\n",
    "    rez5a3.append(w[1])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zferic85/611.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "df1 = pandas.DataFrame({'i': rez5a1, 'ii': rez5a2, 'iii': rez5a3})\n",
    "\n",
    "def visualize(df):\n",
    "    trace1 = go.Histogram(\n",
    "        x=df['i'],\n",
    "        opacity=0.75,\n",
    "        name ='Analytic'\n",
    "    )\n",
    "    trace2 = go.Histogram(\n",
    "        x=df['ii'],\n",
    "        opacity=0.75,\n",
    "        name = 'Batch'\n",
    "    )\n",
    "    trace3 = go.Histogram(\n",
    "        x=df['iii'],\n",
    "        opacity=0.75,\n",
    "        name = 'Stochastic'\n",
    "    )\n",
    "    data = [trace1,trace2,trace3]\n",
    "    layout = go.Layout(barmode='overlay', title = 'Slope Estimates')\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    \n",
    "    return data,layout\n",
    "\n",
    "data,layout = visualize(df1)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "    \n",
    "py.iplot(fig, filename='overlaid histogram1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) analytical solution, \n",
    "(ii) batch\n",
    "(iii) stochastic gradient descent implemented in Question 4.\n",
    "Set learning rate α to a small value (say, α = 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>ii</th>\n",
       "      <th>iii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.981961</td>\n",
       "      <td>2.975315</td>\n",
       "      <td>2.953991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.495785</td>\n",
       "      <td>0.503648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.386048</td>\n",
       "      <td>1.500969</td>\n",
       "      <td>1.111369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.651742</td>\n",
       "      <td>2.648130</td>\n",
       "      <td>2.605460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.014026</td>\n",
       "      <td>2.970718</td>\n",
       "      <td>2.947256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.331852</td>\n",
       "      <td>3.309910</td>\n",
       "      <td>3.295971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.502985</td>\n",
       "      <td>4.693927</td>\n",
       "      <td>4.733961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 i           ii          iii\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean      2.981961     2.975315     2.953991\n",
       "std       0.502551     0.495785     0.503648\n",
       "min       1.386048     1.500969     1.111369\n",
       "25%       2.651742     2.648130     2.605460\n",
       "50%       3.014026     2.970718     2.947256\n",
       "75%       3.331852     3.309910     3.295971\n",
       "max       4.502985     4.693927     4.733961"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b) It seems that all three methods tend to be normally distributed about the mean 3. However, the gradient descent method as shown by the statistics has the best approximate of the intercept and also has the smallest standard deviation. the analytical solution did a little better than the batch gradient descent but then I did not experiment with the tolerance or the number of iterations was fairly low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5c1\n",
      "5c2\n",
      "5c3\n"
     ]
    }
   ],
   "source": [
    "#####testing\n",
    "#Problem 5c\n",
    "\n",
    "rez5c1 = []\n",
    "#analyti square loss\n",
    "print('5c1')\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = analytic(data,target)\n",
    "    #w = batch_gradient(data,target,huber_loss,8000)\n",
    "    rez5c1.append(w[1])\n",
    "#Problem 5b batch square loss\n",
    "print('5c2')\n",
    "rez5c2 = []\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = batch_gradient(data,target,mean_absolute_error,8000)\n",
    "    d = []\n",
    "    rez5c2.append(w[1])\n",
    "#Problem 5c stochastic_square loss\n",
    "print('5c3')\n",
    "rez5c3 = []\n",
    "for i in range(0,1000):\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "    data = list(zip(intercept,X))\n",
    "    target = Y\n",
    "    w = stochastic_gradient(data,target,huber_loss,100)\n",
    "    d = []\n",
    "    rez5c3.append(w[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zferic85/613.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pandas.DataFrame({'i': rez5c1, 'ii': rez5c2, 'iii': rez5c3})\n",
    "\n",
    "data,layout = visualize(df2)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "    \n",
    "py.iplot(fig, filename='overlaid histogram2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) squared loss with the analytical solution, \n",
    "(ii) mean absolute error with batch\n",
    "(iii) Huber loss with batch gradient descent implemented in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>ii</th>\n",
       "      <th>iii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.016011</td>\n",
       "      <td>2.948911</td>\n",
       "      <td>2.998724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491682</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.649229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.629808</td>\n",
       "      <td>0.614442</td>\n",
       "      <td>0.209743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.668698</td>\n",
       "      <td>2.548641</td>\n",
       "      <td>2.574863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.003417</td>\n",
       "      <td>2.927568</td>\n",
       "      <td>2.977030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.328113</td>\n",
       "      <td>3.349467</td>\n",
       "      <td>3.461048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.747849</td>\n",
       "      <td>5.018678</td>\n",
       "      <td>5.319313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 i           ii          iii\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean      3.016011     2.948911     2.998724\n",
       "std       0.491682     0.602151     0.649229\n",
       "min       1.629808     0.614442     0.209743\n",
       "25%       2.668698     2.548641     2.574863\n",
       "50%       3.003417     2.927568     2.977030\n",
       "75%       3.328113     3.349467     3.461048\n",
       "max       4.747849     5.018678     5.319313"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4. Set learning rate α to a small value (say, α = 0.01).\n",
    "\n",
    "\n",
    "#5d) It seems that in this case, the analytical solution outpreformed the rest of the methods. Again, my number of iterations and tolerances were fixed and I did not experiment enough due to run time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#Generate 50 random numbers on interval (0,1]\n",
    "def generate_data():\n",
    "    k = [np.random.rand() for x in range(0,50)]\n",
    "\n",
    "    idx = []\n",
    "    #store index\n",
    "    for i in range(0,50):\n",
    "        if k[i] <= .1: idx.append(i)\n",
    "\n",
    "    X = np.random.uniform(-2,2,50)\n",
    "    e = np.random.normal(0, 4, 50)\n",
    "\n",
    "    Y = 2 + 3*X + e\n",
    "    intercept = [1]*50\n",
    "    data = list(zip(intercept,X))\n",
    "    data = [list(x) for x in data]\n",
    "    for i in idx:\n",
    "        r = np.random.rand()\n",
    "        if r > .5:\n",
    "            data[i][1] = data[i][1] + 1/2*data[i][1]\n",
    "        if r<= .5:\n",
    "            data[i][1] = data[i][1] - 1/2*data[i][1]\n",
    "    return data,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e1\n",
      "5e2\n",
      "5e3\n"
     ]
    }
   ],
   "source": [
    "#####testing\n",
    "#Problem 5c\n",
    "rez5e1 = []\n",
    "print('5e1')\n",
    "#analyti square loss\n",
    "for i in range(0,1000):\n",
    "    data,target = generate_data()\n",
    "    w = analytic(data,target)\n",
    "    rez5e1.append(w[1])\n",
    "#Problem 5b batch square loss\n",
    "rez5e2 = []\n",
    "print('5e2')\n",
    "for i in range(0,1000):\n",
    "    data,target = generate_data()\n",
    "    w = batch_gradient(data,target,mean_absolute_error,8000)\n",
    "    rez5e2.append(w[1])\n",
    "#Problem 5c stochastic_square loss\n",
    "rez5e3 = []\n",
    "print('5e3')\n",
    "for i in range(0,1000):\n",
    "    data,target = generate_data()\n",
    "    w = stochastic_gradient(data,target,huber_loss,100)\n",
    "    rez5e3.append(w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~zferic85/615.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pandas.DataFrame({'i': rez5e1, 'ii': rez5e2, 'iii': rez5e3})\n",
    "\n",
    "data,layout = visualize(df3)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "    \n",
    "py.iplot(fig, filename='overlaid histogram3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>ii</th>\n",
       "      <th>iii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.921184</td>\n",
       "      <td>2.905721</td>\n",
       "      <td>2.915388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499540</td>\n",
       "      <td>0.641434</td>\n",
       "      <td>1.378989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.440308</td>\n",
       "      <td>0.610908</td>\n",
       "      <td>-35.428008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.596092</td>\n",
       "      <td>2.492900</td>\n",
       "      <td>2.510411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.917960</td>\n",
       "      <td>2.925696</td>\n",
       "      <td>2.953779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.267428</td>\n",
       "      <td>3.339575</td>\n",
       "      <td>3.406163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.472105</td>\n",
       "      <td>4.813922</td>\n",
       "      <td>5.470456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 i           ii          iii\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean      2.921184     2.905721     2.915388\n",
       "std       0.499540     0.641434     1.378989\n",
       "min       0.440308     0.610908   -35.428008\n",
       "25%       2.596092     2.492900     2.510411\n",
       "50%       2.917960     2.925696     2.953779\n",
       "75%       3.267428     3.339575     3.406163\n",
       "max       4.472105     4.813922     5.470456"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5f) According to the statistics the closest approximation was achieved by the analytical solution making me believe that my choice of iterations and tolerance needs improvement as well as more experimentation with the huber coeffiecnt. According to \n",
    "the book, the huber loss function should be less sensitive to outliers than the other methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
